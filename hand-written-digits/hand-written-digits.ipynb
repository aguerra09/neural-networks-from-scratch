{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:53:54.063069Z",
     "start_time": "2024-12-21T14:53:54.056411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "7bb263e99aee1401",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Backpropagation algorithm\n",
    "<font size=\"3\">\n",
    "Feedforward (inferencia):\n",
    "$$W · x = y_{pred}$$\n",
    "\n",
    "Backpropagation algorithm (entrenamiento):\n",
    "1. Inicializo los pesos ($W$) de manera aleatoria.\n",
    "2. Obtengo una primera predicción (pobre ya que los pesos son aleatorios). Cuanto de \"pobre\" lo calcula la función de pérdida:$$loss Fn: \\displaystyle\\sum_{k=1}^n(y_{pred} - y_{train})^2$$\n",
    "3. En el entrenamiento, como $x$ (la entrada) e $y_{train}$ (la salida) son fijas, solo se pueden modificar los pesos ($W$) para ajustar la red neuronal.\n",
    "4. Para ajustar $W$ calculamos el gradiente de la función de pérdida ya que el gradiente describe la direción que tomaria $y_{pred}$ al aumentar cualquiera de los valores de $W$: $$grad(\\displaystyle\\sum_{k=1}^n(y_{pred} - y_{train})^2)$$\n",
    "5. Muevo todos los parámetros de $W$ hacia la dirección opuesta del gradiente: $$W =- learningRate * grad·W^T $$\n",
    "</font>"
   ],
   "id": "324d9b531a2c914c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:53:54.777197Z",
     "start_time": "2024-12-21T14:53:54.768230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer_size, hidden_layer_size, output_layer_size):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.output_layer_size = output_layer_size\n",
    "        self.weights_1 = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
    "        self.weights_2 = np.random.randn(self.hidden_layer_size, self.output_layer_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_function(result: np.ndarray, expected: np.ndarray):\n",
    "        return np.mean((result - expected) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feedforward(self, input_data: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        a1 = np.dot(input_data, self.weights_1)\n",
    "        h1 = self.sigmoid(a1)\n",
    "\n",
    "        logging.info(f\"Input data shape: {input_data.shape}\")\n",
    "        logging.info(f\"Weights hidden layer (W1): {self.weights_1.shape}\")\n",
    "        logging.info(f\"Activation hidden layer (h1): {h1.shape}\")\n",
    "\n",
    "        a2 = np.dot(h1, self.weights_2)\n",
    "        probs = self.sigmoid(a2)\n",
    "\n",
    "        logging.info(f\"Weights output layer (W2): {self.weights_2.shape}\")\n",
    "        logging.info(f\"Probabilities: {probs.shape}\")\n",
    "\n",
    "        return probs, h1\n",
    "\n",
    "    def backpropagation(self, x_train: np.ndarray, y_train: np.ndarray, learning_rate):\n",
    "        # Perform forward pass and get predictions and hidden layer activations\n",
    "        probs, h1 = self.feedforward(input_data=x_train)\n",
    "\n",
    "        # Compute output layer error and delta\n",
    "        output_error = probs - y_train\n",
    "        delta_output_layer = output_error * self.sigmoid_derivative(probs)\n",
    "\n",
    "        logging.info(f\"Train label: {y_train.shape}\")\n",
    "        logging.info(f\"Predicted probabilities: {probs.shape}\")\n",
    "        logging.info(f\"Error shape: {output_error.shape}\")\n",
    "        logging.info(f\"Error: {output_error}\")\n",
    "        logging.info(f\"Delta output layer shape: {delta_output_layer.shape}\")\n",
    "\n",
    "        # Compute hidden layer error and delta\n",
    "        hidden_error = np.dot(delta_output_layer, self.weights_2.T)\n",
    "        delta_hidden_layer = hidden_error * self.sigmoid_derivative(h1)\n",
    "\n",
    "        logging.info(f\"Hidden error shape: {hidden_error.shape}\")\n",
    "        logging.info(f\"Hidden derivative shape: {delta_hidden_layer.shape}\")\n",
    "\n",
    "        # Update weights\n",
    "        self.weights_2 += -learning_rate * np.dot(h1.T, delta_output_layer)\n",
    "        self.weights_1 += -learning_rate * np.dot(x_train.T, delta_hidden_layer)\n",
    "\n",
    "        return self.loss_function(probs, y_train)\n",
    "\n",
    "    def train(self, x_train: np.ndarray, y_train: np.ndarray, epochs, learning_rate, print_every: int = 100):\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.backpropagation(x_train, y_train, learning_rate=learning_rate)\n",
    "            if (epoch + 1) % print_every == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        predictions, _ = self.feedforward(x_test)\n",
    "        return predictions"
   ],
   "id": "f80dbbfb2cdf1468",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:53:59.638326Z",
     "start_time": "2024-12-21T14:53:59.634885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_digit(digit: int) -> np.ndarray:\n",
    "    one_hot = np.zeros((10,))\n",
    "    one_hot[digit] = 1\n",
    "    return one_hot\n",
    "\n",
    "def encode_labels(labels_array: np.ndarray) -> np.ndarray:\n",
    "    encoded = [encode_digit(label) for label in labels_array]\n",
    "    return np.array(encoded)"
   ],
   "id": "c48a0442a5c332d0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TRAINING",
   "id": "e88a70363cec6059"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:54:52.665990Z",
     "start_time": "2024-12-21T14:54:52.654313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "digits = datasets.load_digits()\n",
    "training_data = digits.data # Images 8x8pixels -> 64 | 1797 examples -> ndarray (1797, 64)\n",
    "label_data = digits.target # Labels -> ndarray (1797, 1)"
   ],
   "id": "dbe05d94a0647cd1",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:54:53.166284Z",
     "start_time": "2024-12-21T14:54:53.161228Z"
    }
   },
   "cell_type": "code",
   "source": "x_train, x_test, y_train, y_test = train_test_split(training_data, label_data, test_size=0.2, random_state=9)",
   "id": "1ed09ba0695447a0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:54:54.360811Z",
     "start_time": "2024-12-21T14:54:54.356133Z"
    }
   },
   "cell_type": "code",
   "source": "nn = NeuralNetwork(input_layer_size=64, hidden_layer_size=64, output_layer_size=10)",
   "id": "2c3982921d782da",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:54:54.870516Z",
     "start_time": "2024-12-21T14:54:54.866303Z"
    }
   },
   "cell_type": "code",
   "source": "y_train = encode_labels(labels_array=y_train)",
   "id": "d61a96b149c4b0a8",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T14:57:17.055787Z",
     "start_time": "2024-12-21T14:54:55.844095Z"
    }
   },
   "cell_type": "code",
   "source": "nn.train(x_train, y_train, epochs=100000, learning_rate=0.0001, print_every=1000)",
   "id": "7702a2f4f4efae0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/100000, Loss: 0.05643195875216917\n",
      "Epoch 2000/100000, Loss: 0.04016087728621255\n",
      "Epoch 3000/100000, Loss: 0.03185726607378321\n",
      "Epoch 4000/100000, Loss: 0.024672362054829613\n",
      "Epoch 5000/100000, Loss: 0.019525144491253234\n",
      "Epoch 6000/100000, Loss: 0.01498641402646416\n",
      "Epoch 7000/100000, Loss: 0.011834645988089304\n",
      "Epoch 8000/100000, Loss: 0.010157265815163567\n",
      "Epoch 9000/100000, Loss: 0.00906813437585144\n",
      "Epoch 10000/100000, Loss: 0.008175835323130373\n",
      "Epoch 11000/100000, Loss: 0.007458015297302915\n",
      "Epoch 12000/100000, Loss: 0.006874398660183108\n",
      "Epoch 13000/100000, Loss: 0.006397111947987763\n",
      "Epoch 14000/100000, Loss: 0.006012865481931715\n",
      "Epoch 15000/100000, Loss: 0.005696524922762519\n",
      "Epoch 16000/100000, Loss: 0.0053682094575108795\n",
      "Epoch 17000/100000, Loss: 0.004918978401308121\n",
      "Epoch 18000/100000, Loss: 0.004618047573477933\n",
      "Epoch 19000/100000, Loss: 0.004385345679886389\n",
      "Epoch 20000/100000, Loss: 0.004206348325943985\n",
      "Epoch 21000/100000, Loss: 0.004047587591570223\n",
      "Epoch 22000/100000, Loss: 0.003918151203339457\n",
      "Epoch 23000/100000, Loss: 0.003805175640807696\n",
      "Epoch 24000/100000, Loss: 0.0037066006762752996\n",
      "Epoch 25000/100000, Loss: 0.0036205057122803124\n",
      "Epoch 26000/100000, Loss: 0.003545592071666263\n",
      "Epoch 27000/100000, Loss: 0.003457264396861386\n",
      "Epoch 28000/100000, Loss: 0.0033780449234128394\n",
      "Epoch 29000/100000, Loss: 0.003297030283658533\n",
      "Epoch 30000/100000, Loss: 0.003166134249952167\n",
      "Epoch 31000/100000, Loss: 0.003088467487142402\n",
      "Epoch 32000/100000, Loss: 0.002967523844549142\n",
      "Epoch 33000/100000, Loss: 0.0028764903789683517\n",
      "Epoch 34000/100000, Loss: 0.002819617993496458\n",
      "Epoch 35000/100000, Loss: 0.0027743607271317975\n",
      "Epoch 36000/100000, Loss: 0.0027327677469690817\n",
      "Epoch 37000/100000, Loss: 0.0026935630983378344\n",
      "Epoch 38000/100000, Loss: 0.0026558959426242084\n",
      "Epoch 39000/100000, Loss: 0.0026206108439352734\n",
      "Epoch 40000/100000, Loss: 0.002587849470684958\n",
      "Epoch 41000/100000, Loss: 0.0025552406342707517\n",
      "Epoch 42000/100000, Loss: 0.0025214079065137046\n",
      "Epoch 43000/100000, Loss: 0.0024922319904353233\n",
      "Epoch 44000/100000, Loss: 0.002463712705334941\n",
      "Epoch 45000/100000, Loss: 0.002430700001204407\n",
      "Epoch 46000/100000, Loss: 0.0023927933341973792\n",
      "Epoch 47000/100000, Loss: 0.0023623044618987076\n",
      "Epoch 48000/100000, Loss: 0.0023367261610396733\n",
      "Epoch 49000/100000, Loss: 0.0023105185153328585\n",
      "Epoch 50000/100000, Loss: 0.002286009867850249\n",
      "Epoch 51000/100000, Loss: 0.002263548648188427\n",
      "Epoch 52000/100000, Loss: 0.0022391961560483922\n",
      "Epoch 53000/100000, Loss: 0.0022157538805099024\n",
      "Epoch 54000/100000, Loss: 0.0021928127864190208\n",
      "Epoch 55000/100000, Loss: 0.0021633022227725753\n",
      "Epoch 56000/100000, Loss: 0.002134093648495163\n",
      "Epoch 57000/100000, Loss: 0.0021093261004925022\n",
      "Epoch 58000/100000, Loss: 0.00207855611458126\n",
      "Epoch 59000/100000, Loss: 0.0020500385906747536\n",
      "Epoch 60000/100000, Loss: 0.002015284308075009\n",
      "Epoch 61000/100000, Loss: 0.001991936957681973\n",
      "Epoch 62000/100000, Loss: 0.0019724114994312783\n",
      "Epoch 63000/100000, Loss: 0.001954663762752714\n",
      "Epoch 64000/100000, Loss: 0.0019379702432318238\n",
      "Epoch 65000/100000, Loss: 0.0019179084102575051\n",
      "Epoch 66000/100000, Loss: 0.0018979650763968627\n",
      "Epoch 67000/100000, Loss: 0.0018825904015949127\n",
      "Epoch 68000/100000, Loss: 0.0018683581505870696\n",
      "Epoch 69000/100000, Loss: 0.0018547428074862427\n",
      "Epoch 70000/100000, Loss: 0.00184151291236623\n",
      "Epoch 71000/100000, Loss: 0.0018283803219941934\n",
      "Epoch 72000/100000, Loss: 0.0018149137605327323\n",
      "Epoch 73000/100000, Loss: 0.0018011908503767393\n",
      "Epoch 74000/100000, Loss: 0.0017542437377171636\n",
      "Epoch 75000/100000, Loss: 0.0017270751211422833\n",
      "Epoch 76000/100000, Loss: 0.001712487114965\n",
      "Epoch 77000/100000, Loss: 0.0016995831879186491\n",
      "Epoch 78000/100000, Loss: 0.001687458606296241\n",
      "Epoch 79000/100000, Loss: 0.0016758956362952207\n",
      "Epoch 80000/100000, Loss: 0.0016647276311105902\n",
      "Epoch 81000/100000, Loss: 0.0016535462107112907\n",
      "Epoch 82000/100000, Loss: 0.0016411896190847812\n",
      "Epoch 83000/100000, Loss: 0.0016288814125025178\n",
      "Epoch 84000/100000, Loss: 0.0016179082571000966\n",
      "Epoch 85000/100000, Loss: 0.0016076913782799797\n",
      "Epoch 86000/100000, Loss: 0.0015978285095056479\n",
      "Epoch 87000/100000, Loss: 0.0015879154355712577\n",
      "Epoch 88000/100000, Loss: 0.001577757388772593\n",
      "Epoch 89000/100000, Loss: 0.0015683138409779821\n",
      "Epoch 90000/100000, Loss: 0.0015594390126000203\n",
      "Epoch 91000/100000, Loss: 0.001550879105512816\n",
      "Epoch 92000/100000, Loss: 0.0015424935400976285\n",
      "Epoch 93000/100000, Loss: 0.0015341320206641892\n",
      "Epoch 94000/100000, Loss: 0.0015254982781184809\n",
      "Epoch 95000/100000, Loss: 0.001516488656047478\n",
      "Epoch 96000/100000, Loss: 0.0015077886223010123\n",
      "Epoch 97000/100000, Loss: 0.0014995125682110504\n",
      "Epoch 98000/100000, Loss: 0.0014915523993207678\n",
      "Epoch 99000/100000, Loss: 0.0014837735938247314\n",
      "Epoch 100000/100000, Loss: 0.001475907319606965\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "c16fe754c832c168"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T15:10:12.724902Z",
     "start_time": "2024-12-21T15:10:12.709229Z"
    }
   },
   "cell_type": "code",
   "source": "probs = nn.predict(x_test[1])",
   "id": "96de361caddb0669",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T15:10:42.433012Z",
     "start_time": "2024-12-21T15:10:42.427620Z"
    }
   },
   "cell_type": "code",
   "source": "x_test[1]\n",
   "id": "ba14d22b33896451",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  2., 16., 10.,  0.,  0.,  0.,  0.,  0.,  3., 16., 16.,\n",
       "        1.,  0.,  0.,  0.,  0.,  5., 16., 14.,  0.,  0.,  0.,  0.,  0.,\n",
       "        3., 16., 13.,  0.,  0.,  0.,  0.,  0.,  1., 16., 15.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1., 16., 16.,  0.,  0.,  0.,  0.,  0.,  2., 16.,\n",
       "       15.,  2.,  0.,  0.,  0.,  0.,  0., 15., 16., 11.,  0.,  0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T15:10:14.201449Z",
     "start_time": "2024-12-21T15:10:14.196579Z"
    }
   },
   "cell_type": "code",
   "source": "probs",
   "id": "99065b0e75e41b49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.67972723e-08, 9.89390290e-01, 1.13926381e-02, 7.77410380e-03,\n",
       "       2.07566777e-04, 4.63862427e-05, 2.93563582e-04, 4.16311842e-05,\n",
       "       1.26917194e-05, 6.11012076e-08])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T15:06:10.555540Z",
     "start_time": "2024-12-21T15:06:10.552247Z"
    }
   },
   "cell_type": "code",
   "source": "y_test[5]",
   "id": "4d1d4fd4c6ddfd54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T15:06:16.868632Z",
     "start_time": "2024-12-21T15:06:16.766274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.matshow(x_test[5].reshape(8,8), cmap='grey')\n",
    "plt.show()"
   ],
   "id": "a9e042bf3282b95c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
